{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Machine_Learning.kristaps' from 'Machine_Learning/kristaps.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Machine_Learning.elo import *\n",
    "import datetime as dt\n",
    "from Machine_Learning import kristaps\n",
    "from __future__ import division\n",
    "\n",
    "reload(kristaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "filename = 'data/contrived.pickle'\n",
    "data = pd.read_pickle(filename)\n",
    "data = data[:-5000]\n",
    "train = data.iloc[:-300]\n",
    "test = data.iloc[-300:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = train['A Win']\n",
    "X_train = train[['Fran_5_PTS','Opp_5_PTS']]\n",
    "\n",
    "Y_test = test['A Win']\n",
    "X_test = test[['Fran_5_PTS','Opp_5_PTS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM_model = svm.SVC().fit(X_train,Y_train)\n",
    "prob = np.sum(SVM_model.predict(X_test) == Y_test)/len(Y_test)\n",
    "print prob\n",
    "\n",
    "# Holy slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "lam = 10**2\n",
    "\n",
    "sk_logreg = lm.LogisticRegression(C=np.abs(1/lam))\n",
    "sk_logreg.fit(X_train, Y_train)\n",
    "print (sk_logreg.predict(X_test) == Y_test).mean()\n",
    "\n",
    "# Surpsingly(maybe not) good, very fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge as ri\n",
    "\n",
    "skRidge = ri()\n",
    "skRidge.fit(X_train, Y_train)\n",
    "#Print this to see its not empty\n",
    "#print (skRidge.predict(X_test))\n",
    "print (skRidge.predict(X_test) == Y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "gbc = GBC(max_leaf_nodes=200, min_weight_fraction_leaf=0.5,min_samples_split=54).fit(X_train,Y_train)\n",
    "print (np.mean(np.abs(gbc.predict(X_test) - Y_test)))\n",
    "\n",
    "# Fine tuning seems to have minimal effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "\n",
    "gbm = mlp(solver=\"lbfgs\", activation='tanh', early_stopping=True).fit(X_train,Y_train)\n",
    "print (np.mean(np.abs(gbm.predict(X_test) - Y_test)))\n",
    "\n",
    "# Super slow, fine tuning doesnt seem to help much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.443333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "rfc = RFC(max_leaf_nodes=100000, min_samples_split=3, n_estimators =80).fit(X_train,Y_train)\n",
    "print (np.mean(np.abs(rfc.predict(X_test) - Y_test)))\n",
    "\n",
    "# Fine tuned parameters, this is the best I could get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.436666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "dtc = DTC(criterion='entropy').fit(X_train,Y_train)\n",
    "print (np.mean(np.abs(dtc.predict(X_test) - Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algorithms we chose not to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Nearest neighbor\n",
    "\n",
    "Due to the fact that we are not performing any kind of cluster analysis, we have decided the NN-classifying and NN-regression algorithms are not useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian discriminant analysis\n",
    "\n",
    "Similar to the issues with nearest neighbor, since we are not doing any kind of classification, GDA will not be useful with our data set or our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture models with latent variables (train with EM)\n",
    "\n",
    "Because there is not an unknown distribution in our dataset, mixture models along with EM will not work with our data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filters\n",
    "\n",
    "Our data is not a true time series because we are not interested in how teams' overall performances changes over time. Games are decided strictly by winners and losers, so there is not any measurable error or noise. Because of this we have determined that it will not be useful in our methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR, MA, ARMA, ARIMA time series models\n",
    "\n",
    "Because these models are trying to describe certain time-varying processes of a time series, they will not be helpful in trying to predict wins and losses of specific games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
