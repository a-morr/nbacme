{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "filename = 'Algorithms_Data.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data = data[-15000:]\n",
    "targets = data['Win']\n",
    "data = data[['fran_elo', 'opp_elo', 'RollAvg_A_5_pts', 'RollAvg_B_5_pts', 'RollAvg_A_5_opp_pts', 'RollAvg_B_5_opp_pts', 'Days_Since_Last']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runAlgorithm(model, trials=10):\n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    preds =[]\n",
    "    for t in range(trials):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=.2)\n",
    "        t1.append(time.time())\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds.append(model.predict(X_test) == y_test)\n",
    "        t2.append(time.time())\n",
    "        \n",
    "    return np.mean(preds),np.mean(np.array(t2)-np.array(t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Guess that the home team wins every game.  If a method doesn't do better than this, it isn't learning much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573333333333\n"
     ]
    }
   ],
   "source": [
    "print (np.zeros(300) == Y_test).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.616666666667\n",
      "time:  3.7990000248\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Normalize data\n",
    "X = preprocessing.scale(X_train)\n",
    "\n",
    "s = time.time()\n",
    "SVM_model = svm.SVC(C=10**-5, kernel='poly', coef0=0, gamma=10**-2).fit(X, Y_train)\n",
    "preds = SVM_model.predict(X_test)\n",
    "prob = np.sum(preds == Y_test)/len(Y_test)\n",
    "svm_time = time.time() - s\n",
    "print prob\n",
    "print 'time: ', svm_time\n",
    "#print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75880666666666663, 0.02807000160217285)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "lam = 10**2\n",
    "\n",
    "model = lm.LogisticRegression(C=np.abs(1/lam))\n",
    "runAlgorithm(model,trials = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge as ri\n",
    "\n",
    "skRidge = ri()\n",
    "skRidge.fit(X_train, Y_train)\n",
    "preds = skRidge.predict(X_test) > .5\n",
    "print (preds == Y_test).mean()\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74130666666666667, 0.77775991201400752)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "#start = time.time()\n",
    "gbc = GBC(max_leaf_nodes=500, min_weight_fraction_leaf=0.001, min_samples_split=100, learning_rate=.4, max_features=\"auto\")#.fit(X_train,Y_train)\n",
    "\"\"\"preds = gbc.predict(X_test)\n",
    "gradient_boost_time = time.time()-start\n",
    "print (preds == Y_test).mean()\n",
    "print 'time: ' + str(gradient_boost_time)\"\"\"\n",
    "runAlgorithm(gbc, trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.723333333333\n",
      "time: 8.35599994659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "\n",
    "start = time.time()\n",
    "gbm = mlp(solver=\"lbfgs\", activation='tanh', tol=1e-4, alpha=1e-5).fit(X_train,Y_train)\n",
    "print (gbm.predict(X_test) == Y_test).mean()\n",
    "mlp_time = time.time()-start\n",
    "print 'time: ' + str(mlp_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "rfc = RFC(min_samples_split=3, n_estimators =100).fit(X_train,Y_train)\n",
    "print (rfc.predict(X_test) == Y_test).mean()\n",
    "\n",
    "# Fine tuned parameters, this is the best I could get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "dtc = DTC(criterion='entropy').fit(X_train,Y_train)\n",
    "preds = dtc.predict(X_test)\n",
    "print (preds == Y_test).mean()\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "bst = xgb.train({}, dtrain)\n",
    "preds = bst.predict(dtest) > .5\n",
    "print (preds == Y_test).mean()\n",
    "print preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algorithms we chose not to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Nearest neighbor\n",
    "\n",
    "Due to the fact that we are not performing any kind of cluster analysis, we have decided the NN-classifying and NN-regression algorithms are not useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian discriminant analysis\n",
    "\n",
    "Similar to the issues with nearest neighbor, since we are not doing any kind of classification, GDA will not be useful with our data set or our project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixture models with latent variables (train with EM)\n",
    "\n",
    "Because there is not an unknown distribution in our dataset, mixture models along with EM will not work with our data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Filters\n",
    "\n",
    "Our data is not a true time series because we are not interested in how teams' overall performances changes over time. Games are decided strictly by winners and losers, so there is not any measurable error or noise. Because of this we have determined that it will not be useful in our methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR, MA, ARMA, ARIMA time series models\n",
    "\n",
    "Because these models are trying to describe certain time-varying processes of a time series, they will not be helpful in trying to predict wins and losses of specific games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
