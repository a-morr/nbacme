{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "filename = 'Algorithms_Data.csv'\n",
    "data = pd.read_csv(filename)\n",
    "data = data[-15000:]\n",
    "targets = data['Win']\n",
    "data = data[['A_elo', 'B_elo', 'RollAvg_A_5_pts', 'RollAvg_B_5_pts', 'RollAvg_A_5_opp_pts', 'RollAvg_B_5_opp_pts', 'Days_Since_Last']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_elo</th>\n",
       "      <th>B_elo</th>\n",
       "      <th>RollAvg_A_5_pts</th>\n",
       "      <th>RollAvg_B_5_pts</th>\n",
       "      <th>RollAvg_A_5_opp_pts</th>\n",
       "      <th>RollAvg_B_5_opp_pts</th>\n",
       "      <th>Days_Since_Last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32530</th>\n",
       "      <td>1489.768214</td>\n",
       "      <td>1684.042297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>95.2</td>\n",
       "      <td>96.2</td>\n",
       "      <td>86.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>1569.508971</td>\n",
       "      <td>1558.067109</td>\n",
       "      <td>83.8</td>\n",
       "      <td>93.2</td>\n",
       "      <td>77.4</td>\n",
       "      <td>84.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>1687.615767</td>\n",
       "      <td>1528.192875</td>\n",
       "      <td>107.2</td>\n",
       "      <td>98.2</td>\n",
       "      <td>94.2</td>\n",
       "      <td>92.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>1509.910406</td>\n",
       "      <td>1448.525491</td>\n",
       "      <td>101.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.8</td>\n",
       "      <td>97.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32534</th>\n",
       "      <td>1456.563819</td>\n",
       "      <td>1571.171564</td>\n",
       "      <td>97.4</td>\n",
       "      <td>93.6</td>\n",
       "      <td>91.2</td>\n",
       "      <td>83.6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             A_elo        B_elo  RollAvg_A_5_pts  RollAvg_B_5_pts  \\\n",
       "32530  1489.768214  1684.042297             91.8             95.2   \n",
       "32531  1569.508971  1558.067109             83.8             93.2   \n",
       "32532  1687.615767  1528.192875            107.2             98.2   \n",
       "32533  1509.910406  1448.525491            101.2            100.0   \n",
       "32534  1456.563819  1571.171564             97.4             93.6   \n",
       "\n",
       "       RollAvg_A_5_opp_pts  RollAvg_B_5_opp_pts  Days_Since_Last  \n",
       "32530                 96.2                 86.8              1.0  \n",
       "32531                 77.4                 84.4              1.0  \n",
       "32532                 94.2                 92.2              1.0  \n",
       "32533                106.8                 97.6              1.0  \n",
       "32534                 91.2                 83.6              3.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The above table is a sample of the data we will be using in order to predict whether the home team will win an NBA basketball game. Each row represents one match up between two basketball teams. Team A is the home team, team B is the away team.  \n",
    "\n",
    "The ELO rating system is a method for calculating the relative skill levels of players in two-player games such as chess. We have adapted this system in order to measure skill levels of different NBA teams based on their recent performance.  We computed the ELO ratings for each team over the history of our dataset, and we use this as a feature.\n",
    "\n",
    "A_elo: The ELO ranking for the home team (A) at the time this game was played.\n",
    "\n",
    "B_elo: The ELO ranking for the away team (B) at the time this game was played.\n",
    "\n",
    "RollAvg_A_5_pts: For the home team, the average points this specific team has scored in their last 5 games.\n",
    "\n",
    "RollAvg_B_5_pts: For the away team, the average points this specific team has scored in their last 5 games.\n",
    "\n",
    "RollAvg_A_5_opp_pts: For the home team, the average points this specific team has allowed in their last 5 games.\n",
    "\n",
    "RollAvg_B_5_opp_pts: For away team, the average points this specific team has allowed in their last 5 games.\n",
    "\n",
    "Days_Since_Last: Number of days since the home team last played a game.\n",
    "\n",
    "For more information on ELO, see our Machine Learning page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runAlgorithm(model, trials=10,):\n",
    "    \"\"\" Run a given machine learning algorithm on globally defined data.\n",
    "        Splits data randomly into test and training sets.\n",
    "        Returns the average time and accuracy.\n",
    "    \n",
    "    :param model: A sklearn model initialized with parameters.\n",
    "    :param trials: Number of trials to run.  Defaults to 10.\n",
    "    \"\"\"\n",
    "    \n",
    "    t1 = []\n",
    "    t2 = []\n",
    "    preds =[]\n",
    "    for t in range(trials):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=.2)\n",
    "        t1.append(time.time())\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds.append((model.predict(X_test)>.5) == y_test)\n",
    "        t2.append(time.time())\n",
    "        \n",
    "    return np.mean(preds),np.mean(np.array(t2)-np.array(t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of ML algorithms\n",
    "\n",
    "## Baseline\n",
    "Guess that the home team wins every game.  If a method doesn't do better than this, it isn't learning much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.593766666667\n",
      "Time: 0.000300002098083\n"
     ]
    }
   ],
   "source": [
    "t1 = []\n",
    "t2 = []\n",
    "preds = []\n",
    "for t in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=.2)\n",
    "    t1.append(time.time())\n",
    "\n",
    "    preds.append((np.zeros(len(y_test)) == y_test).mean())\n",
    "    t2.append(time.time())\n",
    "\n",
    "baseline_ = np.mean(preds), np.mean(np.array(t2)-np.array(t1))\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*baseline_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652727272727\n",
      "Time: 3.0811818513\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Normalize data\n",
    "X = preprocessing.scale(X_train)\n",
    "\n",
    "accuracy = []\n",
    "times = []\n",
    "for i in xrange(11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=.2)\n",
    "    X = preprocessing.scale(X_train)\n",
    "    s = time.time()\n",
    "    SVM_model = svm.SVC(C=10**-5, kernel='poly', coef0=0, gamma=10**-2).fit(X, y_train)\n",
    "    preds = SVM_model.predict(X_test)\n",
    "    prob = np.sum(preds == y_test)/len(y_test)\n",
    "    times.append(time.time() - s)\n",
    "    accuracy.append(prob)\n",
    "\n",
    "svm_r = (np.mean(accuracy), np.mean(times))\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*svm_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759096666667\n",
      "Time: 0.0327799868584\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model as lm\n",
    "\n",
    "lam = 10**2\n",
    "\n",
    "model = lm.LogisticRegression(C=np.abs(1/lam))\n",
    "log_reg = runAlgorithm(model, trials=100)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge as ri\n",
    "\n",
    "skRidge = ri()\n",
    "rid_reg = runAlgorithm(model,trials = 10)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*rid_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.758602666667\n",
      "Time: 0.00719099807739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_ = runAlgorithm(model,100)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*lda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75611\n",
      "Time: 0.00387000083923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "model = QuadraticDiscriminantAnalysis()\n",
    "qda_= runAlgorithm(model, 100)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*qda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.741476666667\n",
      "Time: 0.720160024166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "\n",
    "#start = time.time()\n",
    "gbc = GBC(max_leaf_nodes=500, min_weight_fraction_leaf=0.001, min_samples_split=100, learning_rate=.4, max_features=\"auto\")\n",
    "grad = runAlgorithm(gbc, trials=100)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.732533333333\n",
      "Time: 7.18240003586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlp\n",
    "\n",
    "start = time.time()\n",
    "gbm = mlp(solver=\"lbfgs\", activation='tanh', tol=1e-4, alpha=1e-5)#.fit(X_train,Y_train)\n",
    "mlp_r = runAlgorithm(gbm, trials=10)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*mlp_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7428\n",
      "Time: 1.59470002651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "rfc = RFC(min_samples_split=3, n_estimators =100)\n",
    "forest = runAlgorithm(rfc, trials=10)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.664233333333\n",
      "Time: 0.0975999832153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "dtc = DTC(criterion='entropy')\n",
    "tree = runAlgorithm(dtc, trials=100)\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.74051515151515157, 0.063956282355568619)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "accuracy = []\n",
    "times = []\n",
    "for i in xrange(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, targets, test_size=.2)\n",
    "    start = time.time()\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "    param = {'objective':'multi:softmax', 'num_class':5,'normalize_type':'forest','rate_drop':1, 'lambda':50, 'alpha':10}\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dtest) > .5\n",
    "    accuracy.append((preds == y_test).mean())\n",
    "    times.append(time.time() -start)\n",
    "    #print preds\n",
    "\n",
    "xgb_r = (np.mean(accuracy), np.mean(times))\n",
    "print 'Accuracy: {}\\nTime: {}'.format(*xgb_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.761733</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>0.032780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.758603</td>\n",
       "      <td>0.007191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.756110</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.742800</td>\n",
       "      <td>1.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.741477</td>\n",
       "      <td>0.720160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.732533</td>\n",
       "      <td>7.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.664233</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.652727</td>\n",
       "      <td>3.081182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.593767</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Accuracy      Time\n",
       "0      Ridge Regression  0.761733  0.031500\n",
       "1   Logistic Regression  0.759097  0.032780\n",
       "2                   LDA  0.758603  0.007191\n",
       "3                   QDA  0.756110  0.003870\n",
       "4         Random Forest  0.742800  1.594700\n",
       "5        Gradient Boost  0.741477  0.720160\n",
       "6                   MLP  0.732533  7.182400\n",
       "7         Decision Tree  0.664233  0.097600\n",
       "8                   SVM  0.652727  3.081182\n",
       "9              Baseline  0.593767  0.000300\n",
       "10              XGBoost  0.000000  0.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps = pd.DataFrame(columns=['Algorithm', 'Accuracy', 'Time'])\n",
    "comps['Algorithm'] = ['Baseline', 'SVM', 'Logistic Regression', 'Ridge Regression', \n",
    "                      'Gradient Boost', 'XGBoost',\n",
    "                      'MLP', 'Decision Tree', 'Random Forest', 'LDA', 'QDA']\n",
    "\n",
    "results = [baseline_, svm_r, log_reg, rid_reg, grad, xgb_r, mlp_r, tree, forest, lda_, qda_]\n",
    "comps['Accuracy'] = [m[0] for m in results]\n",
    "comps['Time'] = [m[1] for m in results]\n",
    "comps.sort_values('Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.593767</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.756110</td>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.758603</td>\n",
       "      <td>0.007191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>0.761733</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.759097</td>\n",
       "      <td>0.032780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.664233</td>\n",
       "      <td>0.097600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.741477</td>\n",
       "      <td>0.720160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.742800</td>\n",
       "      <td>1.594700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.652727</td>\n",
       "      <td>3.081182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.732533</td>\n",
       "      <td>7.182400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Accuracy      Time\n",
       "0               XGBoost  0.000000  0.000000\n",
       "1              Baseline  0.593767  0.000300\n",
       "2                   QDA  0.756110  0.003870\n",
       "3                   LDA  0.758603  0.007191\n",
       "4      Ridge Regression  0.761733  0.031500\n",
       "5   Logistic Regression  0.759097  0.032780\n",
       "6         Decision Tree  0.664233  0.097600\n",
       "7        Gradient Boost  0.741477  0.720160\n",
       "8         Random Forest  0.742800  1.594700\n",
       "9                   SVM  0.652727  3.081182\n",
       "10                  MLP  0.732533  7.182400"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comps.sort_values('Time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy and effectiveness of the methods you used and compare the relative strengths and weaknesses of each method for this particular project.  \n",
    "\n",
    "The methods that we focused on were regression based methods, tree based methods, neural nets, and SVMs. \n",
    "\n",
    "#### Regression based\n",
    "Methods used: Logistic Regression, Ridge Regression\n",
    "\n",
    "Both methods worked extremely well, with accuracies around 76% and running in only ~.03 seconds. \n",
    "\n",
    "#### Tree based\n",
    "Methods used: Decision Tree, Random Forest, Gradient Boost, XGBoost\n",
    "\n",
    "Random Forests ran about as accurately as some of our better performers at 74%, but is a much slower method running in about a second and a half. \n",
    "\n",
    "As expected, Decision Trees ran less accurately than Random Forests at 67% but runs much faster at ~.1 seconds. Decision Trees are one of the fasted methods we tested.\n",
    "\n",
    "XGBoost was among the best of the tree methods, both fast and respectably accurate.  However we could not quite get it to surpass the regression methods in accuracy, and those take only half the time.\n",
    "\n",
    "Gradient Boost performed just under XGBoost both in time and accuracy.\n",
    "\n",
    "\n",
    "#### Gaussian Discriminant Analysis\n",
    "Methods used: Linear Discriminant Analysis, Quadratic Discriminant Analysis\n",
    "\n",
    "Despite their simplicity and the lack of parameters to tune, these two methods both achieve accuracy above 75% and run quickly. They are not quite as accurate as the regression methods, but they are about an order of magnitude faster. The fact that this works so well suggests that the wins and losses are somewhat linearly separable.\n",
    "\n",
    "\n",
    "#### Neural nets\n",
    "Methods used: MLP\n",
    "\n",
    "Our Multi Layer Perception (MLP) was as accurate as many of our top performers at ~75%, but was by far our slowest algorithm taking nearly 7.5 seconds to run. As such even though it is accurate, we would not choose to continue working with it because it is so much slower than other algorithms that are equally accurate.\n",
    "\n",
    "#### SVM\n",
    "Our Support Vector Machine ran the worst accuracy out of any of our other methods at 65%. It also was our second slowest methods running at nearly 3 seconds. Because it was outperformed by almost all of our other tests in both categories, we will not continue working with this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Algorithms we chose not to use\n",
    "\n",
    "### Nearest neighbor\n",
    "\n",
    "Due to the fact that we are not performing any kind of cluster analysis, we have decided the NN-classifying and NN-regression algorithms are not useful. \n",
    "\n",
    "### Mixture models with latent variables (train with EM)\n",
    "\n",
    "Because there is not an unknown distribution in our dataset, mixture models along with EM will not work with our data set.\n",
    "\n",
    "\n",
    "### Kalman Filters\n",
    "\n",
    "Our data is not a true time series because we are not interested in how teams' overall performances changes over time. Games are decided strictly by winners and losers, so there is not any measurable error or noise. Because of this we have determined that it will not be useful in our methods. \n",
    "\n",
    "### AR, MA, ARMA, ARIMA time series models\n",
    "\n",
    "Because these models are trying to describe certain time-varying processes of a time series, they will not be helpful in trying to predict wins and losses of specific games. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
